{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ec5402",
   "metadata": {},
   "source": [
    "# Help Desk Scheduling with PuLP (Colab Ready)\n",
    "\n",
    "This notebook shows how to experiment with the standalone `scheduler_lp` module in a cloud environment such as Google Colab.\n",
    "It downloads the latest module files directly from GitHub, installs the required solver dependency, and\n",
    "walks through building a toy rostering instance that you can adapt for your own data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1631494e",
   "metadata": {},
   "source": [
    "## 1. Environment setup\n",
    "Run the next two cells once per session to install dependencies and fetch the module files.\n",
    "Feel free to replace the GitHub branch or file URLs if you want to test local changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca28bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies needed for scheduling and Excel ingestion.\n",
    "%pip install --quiet pulp==2.7.0 pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd89d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Download the scheduler_lp module from GitHub so we can import it locally.\"\"\"\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen\n",
    "\n",
    "RAW_BASE = \"https://raw.githubusercontent.com/firepenguindisopanda/INFO3604-help-desk-rostering/routes_v2_fix/scheduler_lp\"\n",
    "FILES = {\n",
    "    \"__init__.py\": f\"{RAW_BASE}/__init__.py\",\n",
    "    \"linear_scheduler.py\": f\"{RAW_BASE}/linear_scheduler.py\",\n",
    "    \"examples.py\": f\"{RAW_BASE}/examples.py\",\n",
    "}\n",
    "\n",
    "target_dir = Path(\"scheduler_lp\")\n",
    "target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for name, url in FILES.items():\n",
    "    with urlopen(url) as response:\n",
    "        data = response.read()\n",
    "    (target_dir / name).write_bytes(data)\n",
    "\n",
    "print(f\"Downloaded {len(FILES)} files into {target_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b0ac2",
   "metadata": {},
   "source": [
    "## 2. Load exported schedule data\n",
    "Use the `scripts/export_scheduler_data.py` helper to generate an Excel workbook locally (or on your VM) and upload it here. The default name in this notebook is `helpdesk_scheduler_inputs.xlsx`, but you can change it if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a53911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "EXCEL_PATH = Path(\"helpdesk_scheduler_inputs.xlsx\")\n",
    "if not EXCEL_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Expected to find {EXCEL_PATH} in the working directory. Upload the Excel export or update EXCEL_PATH.\"\n",
    "    )\n",
    "\n",
    "assistants_df = pd.read_excel(EXCEL_PATH, sheet_name=\"assistants\")\n",
    "availability_df = pd.read_excel(EXCEL_PATH, sheet_name=\"assistant_availability\")\n",
    "courses_df = pd.read_excel(EXCEL_PATH, sheet_name=\"assistant_courses\")\n",
    "shifts_df = pd.read_excel(EXCEL_PATH, sheet_name=\"shifts\")\n",
    "shift_demands_df = pd.read_excel(EXCEL_PATH, sheet_name=\"shift_course_demands\")\n",
    "\n",
    "print(\"Loaded sheets:\")\n",
    "for name, df in {\n",
    "    \"assistants\": assistants_df,\n",
    "    \"assistant_availability\": availability_df,\n",
    "    \"assistant_courses\": courses_df,\n",
    "    \"shifts\": shifts_df,\n",
    "    \"shift_course_demands\": shift_demands_df,\n",
    "}.items():\n",
    "    print(f\"  - {name}: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431deeb0",
   "metadata": {},
   "source": [
    "## 3. Build rostering objects from the Excel data\n",
    "With the sheets in memory we can convert each row into the dataclasses consumed by `scheduler_lp.linear_scheduler`. Feel free to adapt the transformation logic if your organisation tracks additional metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fd2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import time\n",
    "\n",
    "from scheduler_lp import (\n",
    "    AvailabilityWindow,\n",
    "    Assistant,\n",
    "    CourseDemand,\n",
    "    SchedulerConfig,\n",
    "    Shift,\n",
    "    solve_helpdesk_schedule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e2e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ensure_time(value):\n",
    "    if isinstance(value, str):\n",
    "        return datetime.strptime(value, \"%H:%M\").time()\n",
    "    if hasattr(value, \"to_pydatetime\"):\n",
    "        return value.to_pydatetime().time()\n",
    "    if hasattr(value, \"hour\"):\n",
    "        return value\n",
    "    raise ValueError(f\"Unrecognised time value: {value!r}\")\n",
    "\n",
    "\n",
    "availability_map = {\n",
    "    assistant_id: [\n",
    "        AvailabilityWindow(\n",
    "            day_of_week=int(row.day_of_week),\n",
    "            start=_ensure_time(row.start_time),\n",
    "            end=_ensure_time(row.end_time),\n",
    "        )\n",
    "        for row in group.itertuples(index=False)\n",
    "    ]\n",
    "    for assistant_id, group in availability_df.groupby(\"assistant_id\")\n",
    "}\n",
    "\n",
    "course_map = {\n",
    "    assistant_id: sorted({row.course_code.upper() for row in group.itertuples(index=False)})\n",
    "    for assistant_id, group in courses_df.groupby(\"assistant_id\")\n",
    "}\n",
    "\n",
    "assistants = []\n",
    "for row in assistants_df.itertuples(index=False):\n",
    "    if not bool(row.active):\n",
    "        continue\n",
    "    assistants.append(\n",
    "        Assistant(\n",
    "            id=row.assistant_id,\n",
    "            courses=course_map.get(row.assistant_id, []),\n",
    "            availability=availability_map.get(row.assistant_id, []),\n",
    "            min_hours=float(row.hours_minimum or 0),\n",
    "            max_hours=None,\n",
    "            cost_per_hour=float(row.rate or 0.0),\n",
    "        )\n",
    "    )\n",
    "\n",
    "shift_demands_grouped = {\n",
    "    shift_id: [\n",
    "        CourseDemand(\n",
    "            course_code=row.course_code.upper(),\n",
    "            tutors_required=int(row.tutors_required),\n",
    "            weight=float(row.weight) if pd.notna(row.weight) else float(row.tutors_required),\n",
    "        )\n",
    "        for row in group.itertuples(index=False)\n",
    "    ]\n",
    "    for shift_id, group in shift_demands_df.groupby(\"shift_id\")\n",
    "}\n",
    "\n",
    "shifts = []\n",
    "for row in shifts_df.itertuples(index=False):\n",
    "    demands = shift_demands_grouped.get(row.shift_id, [])\n",
    "    if not demands:\n",
    "        continue\n",
    "    min_staff = max(1, int(sum(d.tutors_required for d in demands)))\n",
    "    shifts.append(\n",
    "        Shift(\n",
    "            id=str(row.shift_id),\n",
    "            day_of_week=int(row.day_of_week),\n",
    "            start=_ensure_time(row.start_time),\n",
    "            end=_ensure_time(row.end_time),\n",
    "            course_demands=demands,\n",
    "            min_staff=min_staff,\n",
    "            metadata={\n",
    "                \"schedule_id\": str(row.schedule_id),\n",
    "                \"date\": str(row.date),\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f\"Active assistants loaded: {len(assistants)}\")\n",
    "print(f\"Shifts with demand: {len(shifts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed6c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SchedulerConfig(\n",
    "    course_shortfall_penalty=5.0,\n",
    "    understaffed_penalty=40.0,\n",
    "    min_hours_penalty=12.0,\n",
    "    max_hours_penalty=5.0,\n",
    "    solver_time_limit=120,\n",
    "    log_solver_output=False,\n",
    ")\n",
    "\n",
    "if not assistants or not shifts:\n",
    "    raise ValueError(\"No assistants or shifts were generated. Check the Excel input sheets.\")\n",
    "\n",
    "result = solve_helpdesk_schedule(assistants, shifts, config=config)\n",
    "\n",
    "print(f\"Solver status: {result.status}\")\n",
    "if result.objective_value is not None:\n",
    "    print(f\"Objective value: {result.objective_value:.3f}\")\n",
    "\n",
    "print(\"\\nAssignments:\")\n",
    "if result.assignments:\n",
    "    for assistant_id, shift_id in result.assignments:\n",
    "        print(f\"  - {assistant_id} -> {shift_id}\")\n",
    "else:\n",
    "    print(\"  (none)\")\n",
    "\n",
    "print(\"\\nHours by assistant:\")\n",
    "for assistant_id, hours in sorted(result.assistant_hours.items()):\n",
    "    print(f\"  - {assistant_id}: {hours:.2f} hours\")\n",
    "\n",
    "print(\"\\nCourse shortfalls (shift_id, course_code):\")\n",
    "for key, value in sorted(result.course_shortfalls.items()):\n",
    "    print(f\"  - {key}: {value:.2f}\")\n",
    "\n",
    "print(\"\\nStaff shortfalls (shift_id -> understaffed amount):\")\n",
    "for shift_id, value in sorted(result.staff_shortfalls.items()):\n",
    "    print(f\"  - {shift_id}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52f3f24",
   "metadata": {},
   "source": [
    "## 4. Next steps\n",
    "- Tweak the transformation logic (e.g., cap weekly hours) to mirror your policies.\n",
    "- Adjust penalty weights in `SchedulerConfig` to reflect your priorities.\n",
    "- Inspect `result.to_assignment_matrix()` for easier downstream formatting.\n",
    "- Use the downloaded `examples.py` for more ideas (\"Run Module\" > `python -m scheduler_lp.examples`)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
