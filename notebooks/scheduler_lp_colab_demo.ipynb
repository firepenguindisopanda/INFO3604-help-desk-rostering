{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ec5402",
   "metadata": {},
   "source": [
    "# Help Desk Scheduling with PuLP (Colab Ready)\n",
    "\n",
    "This notebook shows how to experiment with the standalone `scheduler_lp` module in a cloud environment such as Google Colab.\n",
    "It downloads the latest module files directly from GitHub, installs the required solver dependency, and\n",
    "walks through building a toy rostering instance that you can adapt for your own data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1631494e",
   "metadata": {},
   "source": [
    "## 1. Environment setup\n",
    "Run the next two cells once per session to install dependencies and fetch the module files.\n",
    "Feel free to replace the GitHub branch or file URLs if you want to test local changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca28bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies needed for scheduling and Excel ingestion.\n",
    "%pip install --quiet pulp==2.7.0 pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd89d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Download the scheduler_lp module from GitHub so we can import it locally.\"\"\"\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen\n",
    "\n",
    "RAW_BASE = \"https://raw.githubusercontent.com/firepenguindisopanda/INFO3604-help-desk-rostering/routes_v2_fix/scheduler_lp\"\n",
    "FILES = {\n",
    "    \"__init__.py\": f\"{RAW_BASE}/__init__.py\",\n",
    "    \"linear_scheduler.py\": f\"{RAW_BASE}/linear_scheduler.py\",\n",
    "    \"examples.py\": f\"{RAW_BASE}/examples.py\",\n",
    "}\n",
    "\n",
    "target_dir = Path(\"scheduler_lp\")\n",
    "target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for name, url in FILES.items():\n",
    "    with urlopen(url) as response:\n",
    "        data = response.read()\n",
    "    (target_dir / name).write_bytes(data)\n",
    "\n",
    "print(f\"Downloaded {len(FILES)} files into {target_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b0ac2",
   "metadata": {},
   "source": [
    "## 2. Load exported schedule data\n",
    "\n",
    "Use the `scripts/export_scheduler_data.py` helper to generate an Excel workbook locally (or on your VM) and upload it here. The default name in this notebook is `helpdesk_scheduler_inputs.xlsx`, but you can change it if needed.\n",
    "\n",
    "If you're experimenting against a *fresh* database that only has assistants/users seeded (no shifts or shift_course_demand rows yet), export in `pre-schedule` mode or let the notebook synthesize a week of shifts on the fly. The fallback logic below mirrors the production defaults so your PuLP run stays comparable to the CP-SAT generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a53911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "EXCEL_PATH = Path(\"helpdesk_scheduler_inputs.xlsx\")\n",
    "if not EXCEL_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Expected to find {EXCEL_PATH} in the working directory. Upload the Excel export or update EXCEL_PATH.\"\n",
    "    )\n",
    "\n",
    "assistants_df = pd.read_excel(EXCEL_PATH, sheet_name=\"assistants\")\n",
    "availability_df = pd.read_excel(EXCEL_PATH, sheet_name=\"assistant_availability\")\n",
    "courses_df = pd.read_excel(EXCEL_PATH, sheet_name=\"assistant_courses\")\n",
    "shifts_df = pd.read_excel(EXCEL_PATH, sheet_name=\"shifts\")\n",
    "shift_demands_df = pd.read_excel(EXCEL_PATH, sheet_name=\"shift_course_demands\")\n",
    "try:\n",
    "    metadata_df = pd.read_excel(\n",
    "        EXCEL_PATH,\n",
    "        sheet_name=\"metadata\",\n",
    "        header=None,\n",
    "        names=[\"key\", \"value\"],\n",
    "    )\n",
    "except ValueError:  # sheet missing\n",
    "    metadata_df = pd.DataFrame(columns=[\"key\", \"value\"])\n",
    "metadata_lookup = {str(row.key): str(row.value) for row in metadata_df.itertuples(index=False)}\n",
    "\n",
    "print(\"Loaded sheets:\")\n",
    "for name, df in {\n",
    "    \"assistants\": assistants_df,\n",
    "    \"assistant_availability\": availability_df,\n",
    "    \"assistant_courses\": courses_df,\n",
    "    \"shifts\": shifts_df,\n",
    "    \"shift_course_demands\": shift_demands_df,\n",
    "}.items():\n",
    "    print(f\"  - {name}: {len(df)} rows\")\n",
    "\n",
    "if metadata_lookup:\n",
    "    window = metadata_lookup.get(\"synthetic_start_date\"), metadata_lookup.get(\"synthetic_end_date\")\n",
    "    print(\"Metadata hints:\")\n",
    "    for key, value in metadata_lookup.items():\n",
    "        print(f\"  - {key}: {value}\")\n",
    "    if any(window):\n",
    "        print(\"(Synthetic shift parameters detected; notebook will mirror them if fallback is needed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431deeb0",
   "metadata": {},
   "source": [
    "## 3. Build rostering objects from the Excel data\n",
    "With the sheets in memory we can convert each row into the dataclasses consumed by `scheduler_lp.linear_scheduler`. Feel free to adapt the transformation logic if your organisation tracks additional metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fd2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import time\n",
    "\n",
    "from scheduler_lp import (\n",
    "    AvailabilityWindow,\n",
    "    Assistant,\n",
    "    CourseDemand,\n",
    "    SchedulerConfig,\n",
    "    Shift,\n",
    "    solve_helpdesk_schedule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e2e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime, time, timedelta\n",
    "\n",
    "from scheduler_lp import (\n",
    "    AvailabilityWindow,\n",
    "    Assistant,\n",
    "    CourseDemand,\n",
    "    SchedulerConfig,\n",
    "    Shift,\n",
    "    solve_helpdesk_schedule,\n",
    ")\n",
    "\n",
    "DEFAULT_MIN_STAFF = 2\n",
    "DEFAULT_MAX_STAFF = 3\n",
    "DEFAULT_TUTORS_REQUIRED = 2\n",
    "DEFAULT_DAY_START = 9\n",
    "DEFAULT_DAY_END = 17\n",
    "\n",
    "\n",
    "def _ensure_time(value):\n",
    "    if isinstance(value, str):\n",
    "        return datetime.strptime(value, \"%H:%M\").time()\n",
    "    if hasattr(value, \"to_pydatetime\"):\n",
    "        return value.to_pydatetime().time()\n",
    "    if hasattr(value, \"hour\"):\n",
    "        return value\n",
    "    raise ValueError(f\"Unrecognised time value: {value!r}\")\n",
    "\n",
    "\n",
    "def _coerce_date(value):\n",
    "    if not value:\n",
    "        return None\n",
    "    try:\n",
    "        return datetime.fromisoformat(str(value)).date()\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _next_monday(reference=None):\n",
    "    reference = reference or datetime.utcnow().date()\n",
    "    days_ahead = (7 - reference.weekday()) % 7\n",
    "    if days_ahead == 0:\n",
    "        days_ahead = 7\n",
    "    return reference + timedelta(days=days_ahead)\n",
    "\n",
    "\n",
    "def _synthesise_weekly_shifts(course_codes, metadata):\n",
    "    courses = sorted({code.upper() for code in course_codes if isinstance(code, str) and code})\n",
    "    if not courses:\n",
    "        return []\n",
    "\n",
    "    meta = metadata or {}\n",
    "    day_start = int(meta.get(\"synthetic_day_start\", DEFAULT_DAY_START))\n",
    "    day_end = int(meta.get(\"synthetic_day_end\", DEFAULT_DAY_END))\n",
    "    include_weekends = str(meta.get(\"synthetic_include_weekends\", \"False\")).lower() == \"true\"\n",
    "    tutors_required = int(meta.get(\"synthetic_tutors_required\", DEFAULT_TUTORS_REQUIRED))\n",
    "    start_date = _coerce_date(meta.get(\"synthetic_start_date\")) or _next_monday()\n",
    "    end_date = _coerce_date(meta.get(\"synthetic_end_date\")) or (start_date + timedelta(days=4))\n",
    "    if end_date < start_date:\n",
    "        end_date = start_date\n",
    "    schedule_id = str(meta.get(\"schedule_id\", \"synthetic\"))\n",
    "\n",
    "    shift_counter = 1\n",
    "    shifts: list[Shift] = []\n",
    "    for offset in range((end_date - start_date).days + 1):\n",
    "        current = start_date + timedelta(days=offset)\n",
    "        weekday = current.weekday()\n",
    "        if not include_weekends and weekday >= 5:\n",
    "            continue\n",
    "        for hour in range(day_start, day_end):\n",
    "            start_time = time(hour=hour, minute=0)\n",
    "            end_dt = datetime.combine(date(2000, 1, 1), start_time) + timedelta(hours=1)\n",
    "            end_time = end_dt.time()\n",
    "            course_demands = [\n",
    "                CourseDemand(\n",
    "                    course_code=code,\n",
    "                    tutors_required=tutors_required,\n",
    "                    weight=float(tutors_required),\n",
    "                )\n",
    "                for code in courses\n",
    "            ]\n",
    "            shifts.append(\n",
    "                Shift(\n",
    "                    id=f\"synthetic-{shift_counter}\",\n",
    "                    day_of_week=weekday,\n",
    "                    start=start_time,\n",
    "                    end=end_time,\n",
    "                    course_demands=course_demands,\n",
    "                    min_staff=DEFAULT_MIN_STAFF,\n",
    "                    max_staff=DEFAULT_MAX_STAFF,\n",
    "                    metadata={\n",
    "                        \"schedule_id\": schedule_id,\n",
    "                        \"date\": current.isoformat(),\n",
    "                        \"source\": \"synthetic\",\n",
    "                    },\n",
    "                )\n",
    "            )\n",
    "            shift_counter += 1\n",
    "    return shifts\n",
    "\n",
    "\n",
    "metadata_lookup_local = globals().get(\"metadata_lookup\", {})\n",
    "\n",
    "availability_map = {\n",
    "    assistant_id: [\n",
    "        AvailabilityWindow(\n",
    "            day_of_week=int(row.day_of_week),\n",
    "            start=_ensure_time(row.start_time),\n",
    "            end=_ensure_time(row.end_time),\n",
    "        )\n",
    "        for row in group.itertuples(index=False)\n",
    "    ]\n",
    "    for assistant_id, group in availability_df.groupby(\"assistant_id\")\n",
    "}\n",
    "\n",
    "course_map = {\n",
    "    assistant_id: sorted({row.course_code.upper() for row in group.itertuples(index=False)})\n",
    "    for assistant_id, group in courses_df.groupby(\"assistant_id\")\n",
    "}\n",
    "\n",
    "assistants = []\n",
    "for row in assistants_df.itertuples(index=False):\n",
    "    if not bool(row.active):\n",
    "        continue\n",
    "    assistants.append(\n",
    "        Assistant(\n",
    "            id=row.assistant_id,\n",
    "            courses=course_map.get(row.assistant_id, []),\n",
    "            availability=availability_map.get(row.assistant_id, []),\n",
    "            min_hours=float(row.hours_minimum or 0),\n",
    "            max_hours=None,\n",
    "            cost_per_hour=float(row.rate or 0.0),\n",
    "        )\n",
    "    )\n",
    "\n",
    "shift_demands_grouped = {}\n",
    "if not shift_demands_df.empty:\n",
    "    shift_demands_grouped = {\n",
    "        shift_id: [\n",
    "            CourseDemand(\n",
    "                course_code=row.course_code.upper(),\n",
    "                tutors_required=int(row.tutors_required),\n",
    "                weight=float(row.weight) if pd.notna(row.weight) else float(row.tutors_required),\n",
    "            )\n",
    "            for row in group.itertuples(index=False)\n",
    "        ]\n",
    "        for shift_id, group in shift_demands_df.groupby(\"shift_id\")\n",
    "    }\n",
    "\n",
    "shifts: list[Shift] = []\n",
    "if shifts_df.empty or not shift_demands_grouped:\n",
    "    print(\"No persisted shifts/demands detected. Synthesising a default help desk week for experimentation.\")\n",
    "    fallback_courses = courses_df[\"course_code\"].dropna().unique().tolist()\n",
    "    shifts = _synthesise_weekly_shifts(fallback_courses, metadata_lookup_local)\n",
    "    shift_demands_grouped = {shift.id: shift.course_demands for shift in shifts}\n",
    "else:\n",
    "    for row in shifts_df.itertuples(index=False):\n",
    "        demands = shift_demands_grouped.get(row.shift_id, [])\n",
    "        if not demands:\n",
    "            continue\n",
    "        shifts.append(\n",
    "            Shift(\n",
    "                id=str(row.shift_id),\n",
    "                day_of_week=int(row.day_of_week),\n",
    "                start=_ensure_time(row.start_time),\n",
    "                end=_ensure_time(row.end_time),\n",
    "                course_demands=demands,\n",
    "                min_staff=DEFAULT_MIN_STAFF,\n",
    "                max_staff=DEFAULT_MAX_STAFF,\n",
    "                metadata={\n",
    "                    \"schedule_id\": str(row.schedule_id),\n",
    "                    \"date\": str(row.date),\n",
    "                    \"source\": \"database\",\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"Active assistants loaded: {len(assistants)}\")\n",
    "print(f\"Shifts with demand: {len(shifts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed6c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SchedulerConfig(\n",
    "    course_shortfall_penalty=5.0,\n",
    "    understaffed_penalty=40.0,\n",
    "    min_hours_penalty=12.0,\n",
    "    max_hours_penalty=5.0,\n",
    "    solver_time_limit=120,\n",
    "    log_solver_output=False,\n",
    ")\n",
    "\n",
    "if not assistants or not shifts:\n",
    "    raise ValueError(\"No assistants or shifts were generated. Check the Excel input sheets.\")\n",
    "\n",
    "result = solve_helpdesk_schedule(assistants, shifts, config=config)\n",
    "\n",
    "print(f\"Solver status: {result.status}\")\n",
    "if result.objective_value is not None:\n",
    "    print(f\"Objective value: {result.objective_value:.3f}\")\n",
    "\n",
    "print(\"\\nAssignments:\")\n",
    "if result.assignments:\n",
    "    for assistant_id, shift_id in result.assignments:\n",
    "        print(f\"  - {assistant_id} -> {shift_id}\")\n",
    "else:\n",
    "    print(\"  (none)\")\n",
    "\n",
    "print(\"\\nHours by assistant:\")\n",
    "for assistant_id, hours in sorted(result.assistant_hours.items()):\n",
    "    print(f\"  - {assistant_id}: {hours:.2f} hours\")\n",
    "\n",
    "print(\"\\nCourse shortfalls (shift_id, course_code):\")\n",
    "for key, value in sorted(result.course_shortfalls.items()):\n",
    "    print(f\"  - {key}: {value:.2f}\")\n",
    "\n",
    "print(\"\\nStaff shortfalls (shift_id -> understaffed amount):\")\n",
    "for shift_id, value in sorted(result.staff_shortfalls.items()):\n",
    "    print(f\"  - {shift_id}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52f3f24",
   "metadata": {},
   "source": [
    "## 4. Next steps\n",
    "- Tweak the transformation logic (e.g., cap weekly hours) to mirror your policies.\n",
    "- Adjust penalty weights in `SchedulerConfig` to reflect your priorities.\n",
    "- Inspect `result.to_assignment_matrix()` for easier downstream formatting.\n",
    "- Use the downloaded `examples.py` for more ideas (\"Run Module\" > `python -m scheduler_lp.examples`)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
